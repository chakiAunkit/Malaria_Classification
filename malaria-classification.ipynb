{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing necessary libraries.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\nimport torch\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torchvision.datasets import ImageFolder\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking out if GPU is working fine.","metadata":{}},{"cell_type":"code","source":"if(torch.cuda.is_available()):\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\nprint(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformation.","metadata":{}},{"cell_type":"markdown","source":"Transforming the input images into tensor and using some basic data augmentation techniques.","metadata":{}},{"cell_type":"code","source":"stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n\ntransform = transforms.Compose([\n    transforms.Resize((120,120)),\n    transforms.ColorJitter(0.05),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(20),\n    transforms.ToTensor(),\n    transforms.Normalize(*stats, inplace=True)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_dir = '/kaggle/input/cell-images-for-detecting-malaria/cell_images/cell_images'\ntrain_set = ImageFolder(input_dir, transform=transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_set))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Randomly splitting the dataset into train and test.","metadata":{}},{"cell_type":"code","source":"test_size = 0.2\n\nnum_train = len(train_set)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\n\ntest_split = int(np.floor((test_size) * num_train))\ntest_index, train_index = indices[:test_split - 1], indices[test_split - 1:]\n\ntrain_sampler = SubsetRandomSampler(train_index)\ntest_sampler = SubsetRandomSampler(test_index)\n\ntrain_loader = DataLoader(train_set, sampler=train_sampler, batch_size=128)\ntest_loader = DataLoader(train_set, sampler=test_sampler, batch_size=64)\nprint(\"Images in Test set: {}\\nImages in Train set: {}\".format(len(test_index), len(train_index)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes=['infected','uninfected']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper function to visualize our inputs.","metadata":{}},{"cell_type":"code","source":"def imshow(img):\n    img = img / 2 + 0.5  # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    \nimages, labels = next(iter(train_loader))\n\nfig = plt.figure(figsize=(25, 15))\n\nfor i in range(10):\n    ax = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[], title=classes[labels[i]])\n    imshow(images[i])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining the base class for our model.\n\n1. train_step : Takes a batch of input and calculates the loss and returns it.\n2. validation_step : Takes a batch of input, calculates the loss and also the accuracy and stores both of them in a python dictionary.\n3. validation_epoch_end : Takes the output after an epoch, returns the average loss and average accuracy.\n4. epoch_end : Just a basic function. We will use this later to print the losses and accuracy after the end of each epoch.","metadata":{}},{"cell_type":"code","source":"#Defining a helper function which will help us to measure accuracy.\ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\nclass MalariaCellDetectBase(nn.Module):\n    def train_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        acc = accuracy(out, labels)\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n    \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['train_loss'], result['val_loss'], result['val_acc']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating our model.","metadata":{}},{"cell_type":"code","source":"class MalariaNet(MalariaCellDetectBase):\n    \n    def __init__(self):\n        super(MalariaNet, self).__init__()\n        \n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.layer3 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)  \n        )\n        \n        self.flatten = nn.Flatten()\n        \n        self.fc1 = nn.Linear(64*15*15, 512)\n        self.fc2 = nn.Linear(512, 128)\n        self.fc3 = nn.Linear(128, 2)\n        self.drop = nn.Dropout2d(0.2)\n            \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        \n        out = self.flatten(out)\n        \n        out = self.fc1(out)\n        out = F.relu(out)\n        out = self.drop(out)\n        \n        out = self.fc2(out)\n        out = F.relu(out)\n        out = self.drop(out)\n        \n        out = self.fc3(out)\n        \n        return out       ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MalariaNet()\nmodel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking out if the input and output dims are as we expected.","metadata":{}},{"cell_type":"code","source":"for images, labels in train_loader:\n    print(f'shape of images: {images.shape}')\n    out = model(images)\n    print(f'shape of output: {out.shape}')\n    print(f'prediction of first image {out[0]}')\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Moving the model and data to cuda.","metadata":{}},{"cell_type":"code","source":"train_loader = DeviceDataLoader(train_loader, device)\ntest_loader = DeviceDataLoader(test_loader, device)\nto_device(model, device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating our model.","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.train_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = to_device(MalariaNet(), device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking our accuracy just after creating the model.\n\nWe are doing this step so that we can check how well our model improved in the course of time.","metadata":{}},{"cell_type":"code","source":"evaluate(model, test_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining the optimizer and learning rate.","metadata":{}},{"cell_type":"code","source":"learning_rate = 0.0001\noptimizer = torch.optim.Adam\nepochs = 20","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = fit(epochs, learning_rate, model, train_loader, test_loader, opt_func=optimizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accuracies(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_losses(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}